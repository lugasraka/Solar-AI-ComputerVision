{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SolarVision AI: Week 1 - Exploratory Data Analysis\n",
    "\n",
    "**Project**: SolarVision AI - Automated PV Panel Defect Detection\n",
    "**Dataset**: PV Panel Defect Dataset (alicjalena)\n",
    "**Date**: February 2026\n",
    "\n",
    "This notebook contains the comprehensive Exploratory Data Analysis (EDA) for the SolarVision AI project.\n",
    "\n",
    "## Objectives\n",
    "1. Understand dataset structure and splits\n",
    "2. Analyze class distribution across train/val/test\n",
    "3. Examine image characteristics (resolution, format, quality)\n",
    "4. Visualize sample images from each class\n",
    "5. Calculate RGB statistics for normalization\n",
    "6. Identify data quality issues and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "DATASET_ROOT = Path('../dataset')\n",
    "SPLITS = ['train', 'val', 'test']\n",
    "\n",
    "# Verify structure\n",
    "print(\"üìÅ Dataset Structure:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for split in SPLITS:\n",
    "    split_path = DATASET_ROOT / split\n",
    "    if split_path.exists():\n",
    "        classes = sorted([d for d in split_path.iterdir() if d.is_dir()])\n",
    "        print(f\"\\n{split.upper()}/\")\n",
    "        for cls in classes:\n",
    "            print(f\"  ‚îú‚îÄ‚îÄ {cls.name}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per class per split\n",
    "data_stats = []\n",
    "\n",
    "for split in SPLITS:\n",
    "    split_path = DATASET_ROOT / split\n",
    "    if not split_path.exists():\n",
    "        continue\n",
    "    \n",
    "    for class_dir in sorted(split_path.iterdir()):\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        # Count images (supporting multiple extensions)\n",
    "        image_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}\n",
    "        image_count = len([f for f in class_dir.iterdir() \n",
    "                          if f.suffix in image_extensions])\n",
    "        \n",
    "        data_stats.append({\n",
    "            'split': split,\n",
    "            'class': class_dir.name,\n",
    "            'count': image_count\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_stats = pd.DataFrame(data_stats)\n",
    "\n",
    "# Pivot table for better visualization\n",
    "pivot_table = df_stats.pivot(index='class', columns='split', values='count').fillna(0).astype(int)\n",
    "pivot_table['Total'] = pivot_table.sum(axis=1)\n",
    "\n",
    "# Calculate split percentages\n",
    "split_totals = pivot_table[SPLITS].sum()\n",
    "total_images = split_totals.sum()\n",
    "\n",
    "print(\"\\nüìä Image Count per Class per Split:\")\n",
    "print(\"=\" * 70)\n",
    "print(pivot_table)\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(f\"Total Images: {int(total_images)}\")\n",
    "print(\"\\nSplit Distribution:\")\n",
    "for split in SPLITS:\n",
    "    pct = split_totals[split] / total_images * 100\n",
    "    print(f\"  {split:5s}: {int(split_totals[split]):4d} images ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Key Finding: Split Distribution Issue\n",
    "\n",
    "The current split distribution differs significantly from the expected 70/15/15:\n",
    "- **Expected**: Train 70% / Val 15% / Test 15%\n",
    "- **Actual**: Train ~59% / Val ~35% / Test ~6%\n",
    "\n",
    "**Impact**: Test set is too small (only 95 images) for reliable evaluation.\n",
    "\n",
    "**Recommendation**: Consider re-splitting the dataset or combining val+test for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Stacked bar chart\n",
    "pivot_table[SPLITS].plot(kind='bar', stacked=True, ax=axes[0], width=0.8)\n",
    "axes[0].set_title('Image Count per Class by Split', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Defect Class', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Images', fontsize=12)\n",
    "axes[0].legend(title='Split')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Percentage distribution per class\n",
    "class_percentages = pivot_table[SPLITS].div(pivot_table['Total'], axis=0) * 100\n",
    "class_percentages.plot(kind='bar', stacked=True, ax=axes[1], width=0.8)\n",
    "axes[1].set_title('Split Distribution per Class (%)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Defect Class', fontsize=12)\n",
    "axes[1].set_ylabel('Percentage', fontsize=12)\n",
    "axes[1].legend(title='Split')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Format and Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze file formats\n",
    "format_stats = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for split in SPLITS:\n",
    "    split_path = DATASET_ROOT / split\n",
    "    if not split_path.exists():\n",
    "        continue\n",
    "    \n",
    "    for class_dir in split_path.iterdir():\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        for img_file in class_dir.iterdir():\n",
    "            ext = img_file.suffix.lower()\n",
    "            if ext in ['.jpg', '.jpeg', '.png']:\n",
    "                format_stats[split][ext] += 1\n",
    "\n",
    "# Create format summary\n",
    "format_df = pd.DataFrame(format_stats).fillna(0).astype(int)\n",
    "format_df['Total'] = format_df.sum(axis=1)\n",
    "\n",
    "print(\"üì∑ File Format Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "print(format_df)\n",
    "\n",
    "# Calculate percentages\n",
    "print(\"\\nüìä Format Percentages:\")\n",
    "print(\"-\" * 50)\n",
    "for ext in format_df.index:\n",
    "    pct = format_df.loc[ext, 'Total'] / format_df['Total'].sum() * 100\n",
    "    print(f\"{ext:6s}: {int(format_df.loc[ext, 'Total']):4d} images ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image dimensions\n",
    "def get_image_dimensions(dataset_path, sample_size=None):\n",
    "    \"\"\"Extract dimensions from images in dataset.\"\"\"\n",
    "    dimensions = []\n",
    "    image_info = []\n",
    "    \n",
    "    for split in SPLITS:\n",
    "        split_path = dataset_path / split\n",
    "        if not split_path.exists():\n",
    "            continue\n",
    "        \n",
    "        for class_dir in tqdm(list(split_path.iterdir()), desc=f'Processing {split}'):\n",
    "            if not class_dir.is_dir():\n",
    "                continue\n",
    "            \n",
    "            class_name = class_dir.name\n",
    "            image_files = [f for f in class_dir.iterdir() \n",
    "                          if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "            \n",
    "            if sample_size:\n",
    "                image_files = image_files[:sample_size]\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                try:\n",
    "                    with Image.open(img_file) as img:\n",
    "                        width, height = img.size\n",
    "                        mode = img.mode\n",
    "                        dimensions.append({\n",
    "                            'file': img_file.name,\n",
    "                            'class': class_name,\n",
    "                            'split': split,\n",
    "                            'width': width,\n",
    "                            'height': height,\n",
    "                            'mode': mode,\n",
    "                            'aspect_ratio': width / height\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_file}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(dimensions)\n",
    "\n",
    "# Analyze dimensions (using all images)\n",
    "print(\"üîç Analyzing image dimensions...\")\n",
    "df_dims = get_image_dimensions(DATASET_ROOT)\n",
    "print(f\"\\n‚úÖ Analyzed {len(df_dims)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension statistics\n",
    "print(\"\\nüìê Image Dimension Statistics:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total images analyzed: {len(df_dims)}\")\n",
    "print(\"\\nWidth statistics:\")\n",
    "print(df_dims['width'].describe())\n",
    "print(\"\\nHeight statistics:\")\n",
    "print(df_dims['height'].describe())\n",
    "print(\"\\nAspect Ratio statistics:\")\n",
    "print(df_dims['aspect_ratio'].describe())\n",
    "\n",
    "# Color mode distribution\n",
    "print(\"\\nüé® Color Mode Distribution:\")\n",
    "print(df_dims['mode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dimension distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Width distribution\n",
    "axes[0, 0].hist(df_dims['width'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Image Widths', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Width (pixels)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df_dims['width'].median(), color='red', linestyle='--', \n",
    "                   label=f'Median: {df_dims[\"width\"].median():.0f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Height distribution\n",
    "axes[0, 1].hist(df_dims['height'], bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[0, 1].set_title('Distribution of Image Heights', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Height (pixels)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(df_dims['height'].median(), color='red', linestyle='--', \n",
    "                   label=f'Median: {df_dims[\"height\"].median():.0f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Aspect ratio distribution\n",
    "axes[1, 0].hist(df_dims['aspect_ratio'], bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Distribution of Aspect Ratios', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Aspect Ratio (width/height)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].axvline(df_dims['aspect_ratio'].median(), color='red', linestyle='--', \n",
    "                   label=f'Median: {df_dims[\"aspect_ratio\"].median():.2f}')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Scatter plot of width vs height\n",
    "scatter = axes[1, 1].scatter(df_dims['width'], df_dims['height'], \n",
    "                            alpha=0.5, c=df_dims['aspect_ratio'], cmap='viridis')\n",
    "axes[1, 1].set_title('Width vs Height (colored by aspect ratio)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Width (pixels)')\n",
    "axes[1, 1].set_ylabel('Height (pixels)')\n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='Aspect Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('image_dimensions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample images from each class\n",
    "def get_sample_images(dataset_path, samples_per_class=3):\n",
    "    \"\"\"Get sample images from each class.\"\"\"\n",
    "    samples = {}\n",
    "    \n",
    "    # Use training set for samples\n",
    "    train_path = dataset_path / 'train'\n",
    "    \n",
    "    for class_dir in sorted(train_path.iterdir()):\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        class_name = class_dir.name\n",
    "        image_files = [f for f in class_dir.iterdir() \n",
    "                      if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "        \n",
    "        # Get first N samples\n",
    "        samples[class_name] = image_files[:samples_per_class]\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Get samples\n",
    "samples = get_sample_images(DATASET_ROOT, samples_per_class=3)\n",
    "classes = list(samples.keys())\n",
    "\n",
    "print(f\"üì∏ Sample images from {len(classes)} classes\")\n",
    "for cls, imgs in samples.items():\n",
    "    print(f\"  {cls}: {len(imgs)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "n_classes = len(classes)\n",
    "n_samples = 3\n",
    "\n",
    "fig, axes = plt.subplots(n_classes, n_samples, figsize=(15, n_classes * 4))\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    for j in range(n_samples):\n",
    "        if j < len(samples[class_name]):\n",
    "            img_path = samples[class_name][j]\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis('off')\n",
    "            \n",
    "            if j == 0:\n",
    "                axes[i, j].set_ylabel(class_name, fontsize=12, fontweight='bold', rotation=0, \n",
    "                                    labelpad=80, va='center')\n",
    "            \n",
    "            # Add image size as title\n",
    "            axes[i, j].set_title(f'{img.size[0]}x{img.size[1]}', fontsize=9)\n",
    "        else:\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images from Each Defect Class', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RGB Statistics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RGB statistics (sample-based for speed)\n",
    "def calculate_rgb_stats(dataset_path, sample_size=50):\n",
    "    \"\"\"Calculate RGB mean and std (sample-based).\"\"\"\n",
    "    rgb_values = []\n",
    "    \n",
    "    train_path = dataset_path / 'train'\n",
    "    \n",
    "    # Collect sample images from each class\n",
    "    all_images = []\n",
    "    for class_dir in train_path.iterdir():\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        image_files = [f for f in class_dir.iterdir() \n",
    "                      if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "        all_images.extend(image_files)\n",
    "    \n",
    "    # Sample images\n",
    "    np.random.seed(42)\n",
    "    sampled_images = np.random.choice(all_images, \n",
    "                                     size=min(sample_size, len(all_images)), \n",
    "                                     replace=False)\n",
    "    \n",
    "    print(f\"Calculating RGB stats from {len(sampled_images)} sample images...\")\n",
    "    \n",
    "    for img_path in tqdm(sampled_images):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
    "            rgb_values.append(img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    # Stack all images\n",
    "    all_pixels = np.concatenate([img.reshape(-1, 3) for img in rgb_values], axis=0)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = np.mean(all_pixels, axis=0)\n",
    "    std = np.std(all_pixels, axis=0)\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "# Calculate RGB statistics\n",
    "rgb_mean, rgb_std = calculate_rgb_stats(DATASET_ROOT, sample_size=100)\n",
    "\n",
    "print(\"\\nüìä RGB Statistics (Sample-based):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean:  [{rgb_mean[0]:.4f}, {rgb_mean[1]:.4f}, {rgb_mean[2]:.4f}]\")\n",
    "print(f\"Std:   [{rgb_std[0]:.4f}, {rgb_std[1]:.4f}, {rgb_std[2]:.4f}]\")\n",
    "print(\"\\nüìä ImageNet Statistics (for comparison):\")\n",
    "print(\"Mean:  [0.485, 0.456, 0.406]\")\n",
    "print(\"Std:   [0.229, 0.224, 0.225]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Class Balance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class balance\n",
    "train_counts = pivot_table['train']\n",
    "total_train = train_counts.sum()\n",
    "\n",
    "print(\"üìä Class Distribution in Training Set:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Class':<20} {'Count':<8} {'Percentage':<12} {'Balance'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "expected_pct = 100 / len(train_counts)  # Expected if perfectly balanced\n",
    "\n",
    "for cls, count in train_counts.items():\n",
    "    pct = count / total_train * 100\n",
    "    deviation = pct - expected_pct\n",
    "    balance = \"‚úÖ Balanced\" if abs(deviation) < 5 else \"‚ö†Ô∏è  Imbalanced\"\n",
    "    print(f\"{cls:<20} {count:<8} {pct:>6.1f}%      {balance}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total':<20} {total_train:<8}\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "max_class = train_counts.max()\n",
    "min_class = train_counts.min()\n",
    "imbalance_ratio = max_class / min_class\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è  Imbalance Ratio (max/min): {imbalance_ratio:.2f}\")\n",
    "print(f\"   ‚Üí Moderate imbalance, manageable with standard techniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class balance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Pie chart\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(train_counts)))\n",
    "axes[0].pie(train_counts, labels=train_counts.index, autopct='%1.1f%%', \n",
    "           colors=colors, startangle=90)\n",
    "axes[0].set_title('Training Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart with expected line\n",
    "bars = axes[1].bar(range(len(train_counts)), train_counts.values, color=colors, \n",
    "                   edgecolor='black', alpha=0.8)\n",
    "axes[1].axhline(y=expected_pct * total_train / 100, color='red', linestyle='--', \n",
    "               linewidth=2, label=f'Perfect Balance ({expected_pct:.1f}%)')\n",
    "axes[1].set_xticks(range(len(train_counts)))\n",
    "axes[1].set_xticklabels(train_counts.index, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Number of Images', fontsize=12)\n",
    "axes[1].set_title('Training Set Class Counts', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_balance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìà Key Findings\n",
    "\n",
    "#### Dataset Overview\n",
    "- **Total Images**: 1,574 images across 6 defect classes\n",
    "- **Splits**: Train (929), Val (550), Test (95)\n",
    "- **Classes**: Bird-drop, Clean, Dusty, Electrical-damage, Physical-Damage, Snow-Covered\n",
    "\n",
    "#### Split Distribution Issue ‚ö†Ô∏è\n",
    "- **Current**: 59% Train / 35% Val / 6% Test\n",
    "- **Expected**: 70% Train / 15% Val / 15% Test\n",
    "- **Problem**: Test set too small (95 images) for reliable evaluation\n",
    "\n",
    "#### Image Characteristics\n",
    "- **Formats**: 95% JPG, 4% PNG, 1% JPEG\n",
    "- **Dimensions**: Highly variable (190√ó250 to 1920√ó1080+)\n",
    "- **Aspect Ratios**: Ranges from 0.5 to 2.5+\n",
    "- **Color Mode**: All RGB\n",
    "\n",
    "#### Class Balance\n",
    "- **Ratio**: 1.34 (max/min) - moderate imbalance\n",
    "- **Largest**: Bird-drop (177 train images)\n",
    "- **Smallest**: Physical-Damage (132 train images)\n",
    "\n",
    "### ‚úÖ Recommendations\n",
    "\n",
    "1. **Resplit Dataset**: Re-split to 70/15/15 for reliable evaluation\n",
    "2. **Data Augmentation**: Essential due to small dataset size (~929 training images)\n",
    "3. **Preprocessing**: Resize to 224√ó224 with proper aspect ratio handling\n",
    "4. **Normalization**: Use ImageNet statistics [0.485, 0.456, 0.406] / [0.229, 0.224, 0.225]\n",
    "5. **Class Imbalance**: Use weighted sampling or focal loss\n",
    "\n",
    "### üéØ Next Steps (Week 2)\n",
    "\n",
    "1. Implement data preprocessing pipeline\n",
    "2. Create heavy augmentation strategy\n",
    "3. Set up stratified resplitting (optional)\n",
    "4. Prepare PyTorch DataLoader\n",
    "5. Begin model development with ResNet18+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary statistics to CSV\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Images',\n",
    "        'Train Images',\n",
    "        'Val Images',\n",
    "        'Test Images',\n",
    "        'Number of Classes',\n",
    "        'Most Common Format',\n",
    "        'Median Width',\n",
    "        'Median Height',\n",
    "        'Median Aspect Ratio',\n",
    "        'Class Imbalance Ratio',\n",
    "        'RGB Mean (R)',\n",
    "        'RGB Mean (G)',\n",
    "        'RGB Mean (B)',\n",
    "        'RGB Std (R)',\n",
    "        'RGB Std (G)',\n",
    "        'RGB Std (B)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        int(total_images),\n",
    "        int(split_totals['train']),\n",
    "        int(split_totals['val']),\n",
    "        int(split_totals['test']),\n",
    "        len(train_counts),\n",
    "        'JPG (95%)',\n",
    "        f\"{df_dims['width'].median():.0f}\",\n",
    "        f\"{df_dims['height'].median():.0f}\",\n",
    "        f\"{df_dims['aspect_ratio'].median():.2f}\",\n",
    "        f\"{imbalance_ratio:.2f}\",\n",
    "        f\"{rgb_mean[0]:.4f}\",\n",
    "        f\"{rgb_mean[1]:.4f}\",\n",
    "        f\"{rgb_mean[2]:.4f}\",\n",
    "        f\"{rgb_std[0]:.4f}\",\n",
    "        f\"{rgb_std[1]:.4f}\",\n",
    "        f\"{rgb_std[2]:.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('eda_summary.csv', index=False)\n",
    "print(\"‚úÖ Summary statistics saved to 'eda_summary.csv'\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**End of EDA Notebook**\n",
    "\n",
    "*Generated for SolarVision AI Project - Week 1*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}